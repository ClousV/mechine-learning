# K-means
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# 1.data preprocessing
# --------------------------------------------------
# read the file(excel,csv....)
df = pd.read_excel('')

# Extract MJD timestamp and convert it into a two-dimensional array
timestamps = df['MJD'].values.reshape(-1, 1)

# Standardized data (K-Means is sensitive to feature scale)
scaler = StandardScaler()
timestamps_scaled = scaler.fit_transform(timestamps)

# 2. Determine the optimal number of clusters (elbow rule+contour coefficient)
# --------------------------------------------------
max_clusters = 10 # Maximum number of attempted clusters(FRB 2012 and FRB 2014 use 10,FRB 2018 use 100)
inertia = []
silhouette_scores = []

for k in range(2, max_clusters+1):
    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
    kmeans.fit(timestamps_scaled)
    inertia.append(kmeans.inertia_)
    
    # Calculate contour coefficient only when k>1
    if k > 1:
        score = silhouette_score(timestamps_scaled, kmeans.labels_)
        silhouette_scores.append(score)

# Visual evaluation indicators
plt.figure(figsize=(15, 5))

#font settings
plt.rcParams['xtick.labelsize'] = 18  
plt.rcParams['ytick.labelsize'] = 18  
plt.rcParams['axes.labelsize'] = 17   

# Elbow rule diagram
plt.subplot(1, 2, 1)
plt.plot(range(2, max_clusters+1), inertia, 'bo-')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
#plt.title('Elbow Method')

# Silhouette Coefficient Plot
plt.subplot(1, 2, 2)
plt.plot(range(2, max_clusters+1), silhouette_scores, 'ro-')  
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
#plt.title('Silhouette Analysis')
plt.tight_layout()
#plt.savefig('figure5.png', dpi=300)
plt.show()

# 3. Perform K-Means clustering
# --------------------------------------------------
# Manually select the optimal k value (you can also optimize the program to automatically read it)
best_k = int(input("According to the elbow rule and contour coefficient, please enter the optimal number of clusters："))

# Train the final model
final_kmeans = KMeans(n_clusters=best_k, init='k-means++', random_state=42)
final_kmeans.fit(timestamps_scaled)

# Obtain clustering results
cluster_labels = final_kmeans.labels_
centers_scaled = final_kmeans.cluster_centers_

# Convert the clustering center back to the original time unit(MJD)
centers = scaler.inverse_transform(centers_scaled).flatten()
sorted_centers = np.sort(centers)

# 4.Cycle pattern analysis
# --------------------------------------------------
# Calculate inter cluster spacing
gaps = np.diff(sorted_centers)
print("\n Inter cluster interval analysis:")
print(f"average interval: {np.mean(gaps):.2f} days")
print(f"Interval standard deviation: {np.std(gaps):.2f} days")
print("Specific interval days:", np.round(gaps, 2))

# Find approximate period
unique_gaps, counts = np.unique(np.round(gaps, 1), return_counts=True)
common_gap = unique_gaps[np.argmax(counts)]
print(f"\nThe most common approximate interval: {common_gap:.1f} days（appear{counts.max()} times）")

# 5. visualization results
# --------------------------------------------------
plt.figure(figsize=(15, 6))

# Original time distribution
plt.subplot(1, 2, 1)
plt.scatter(df['MJD'], np.zeros_like(df['MJD']), 
            c=cluster_labels, cmap='tab10', s=50, alpha=0.7)
plt.scatter(sorted_centers, np.zeros(best_k), 
            marker='X', s=50, c='red', label='Cluster Centers')
plt.xlabel('TIME(MJD)')
plt.gca().get_yaxis().set_visible(False)
#plt.title('Time distribution and clustering centers of FRB 20121102')
plt.legend()
# Create a legend object first
leg1 = plt.legend()

# Then modify the font size of specific text
for text in leg1.get_texts():
    if "Cluster Centers" in text.get_text():
        text.set_fontsize(15)  

# Interval distribution histogram
plt.subplot(1, 2, 2)
plt.hist(gaps, bins=7, edgecolor='k', alpha=0.7  #(about bins:FRB 2012 and FRB 2014 use 3,FRB 2018 use 7)
plt.axvline(common_gap, color='r', linestyle='--',
           label=f'Common Gap: {common_gap:.1f} days')
plt.xlabel('Time Gap Between Clusters (days)')
plt.ylabel('Frequency')
plt.ylim(0, 20)
#plt.title('Cluster Interval Distribution')
plt.legend()
leg2 = plt.legend()

for text in leg2.get_texts():
    if "Common Gap" in text.get_text():
        text.set_fontsize(15)  
    

plt.tight_layout()
#plt.savefig('figure18.png', dpi=300)
plt.show()

# 6. Output detailed clustering information
# --------------------------------------------------
print("\n Detailed clustering analysis:")
for i, center in enumerate(sorted_centers):
    cluster_events = df[cluster_labels == i]
    print(f"\nCluster {i+1}:")
    print(f"• Central Time: {center:.2f} MJD")
    print(f"• Including the number of events: {len(cluster_events)}")
    print(f"• time range: {cluster_events['TIME(MJD)'].min():.2f} - {cluster_events['MJD'].max():.2f}")
    print(f"• Average SNR: {cluster_events['SNR'].mean():.2f}")
    print(f"• Average DM: {cluster_events['DM'].mean():.2f}")


